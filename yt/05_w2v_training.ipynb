{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load the 20 newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "documents = newsgroups.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and process text data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "\n",
    "class Corpus:\n",
    "    def __init__(self, documents, preprocessor, use_phrases = True):\n",
    "        self.documents = documents\n",
    "        self.preprocessor = preprocessor\n",
    "        self.phrases_have_been_identified = False\n",
    "        if use_phrases:\n",
    "            self._learn_phrases()\n",
    "\n",
    "    def _phrases_identification(self):\n",
    "        for doc in self.documents:\n",
    "            yield self.preprocessor(doc)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for doc in self.documents:\n",
    "            if self.phrases_have_been_identified:\n",
    "                yield self.phrases[self.preprocessor(doc)]\n",
    "            else:\n",
    "                yield self.preprocessor(doc)\n",
    "\n",
    "    def _learn_phrases(self):\n",
    "        self.phrases = Phrases(self._phrases_identification())\n",
    "        self.phrases_have_been_identified = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 11:55:56,776 : INFO : collecting all words and their counts\n",
      "2024-11-22 11:55:56,777 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2024-11-22 11:55:59,267 : INFO : PROGRESS: at sentence #10000, processed 2815610 words and 961694 word types\n",
      "2024-11-22 11:56:01,565 : INFO : collected 1453195 token types (unigram + bigrams) from a corpus of 5227570 words and 18846 sentences\n",
      "2024-11-22 11:56:01,566 : INFO : merged Phrases<1453195 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2024-11-22 11:56:01,566 : INFO : Phrases lifecycle event {'msg': 'built Phrases<1453195 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000> in 4.79s', 'datetime': '2024-11-22T11:56:01.566483', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.0.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-22 11:56:01,578 : INFO : collecting all words and their counts\n",
      "2024-11-22 11:56:01,578 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-11-22 11:56:04,577 : INFO : PROGRESS: at sentence #10000, processed 2481408 words, keeping 107698 word types\n",
      "2024-11-22 11:56:07,373 : INFO : collected 141101 word types from a corpus of 4612072 raw words and 18846 sentences\n",
      "2024-11-22 11:56:07,373 : INFO : Creating a fresh vocabulary\n",
      "2024-11-22 11:56:07,437 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 57418 unique words (40.69% of original 141101, drops 83683)', 'datetime': '2024-11-22T11:56:07.437034', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.0.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-11-22 11:56:07,437 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 4468997 word corpus (96.90% of original 4612072, drops 143075)', 'datetime': '2024-11-22T11:56:07.437576', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.0.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-11-22 11:56:07,527 : INFO : deleting the raw counts dictionary of 141101 items\n",
      "2024-11-22 11:56:07,529 : INFO : sample=0.001 downsamples 41 most-common words\n",
      "2024-11-22 11:56:07,529 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3617175.4613567744 word corpus (80.9%% of prior 4468997)', 'datetime': '2024-11-22T11:56:07.529442', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.0.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-11-22 11:56:07,674 : INFO : estimated required memory for 57418 words and 100 dimensions: 74643400 bytes\n",
      "2024-11-22 11:56:07,675 : INFO : resetting layer weights\n",
      "2024-11-22 11:56:07,689 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-11-22T11:56:07.689212', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.0.1-arm64-arm-64bit', 'event': 'build_vocab'}\n",
      "2024-11-22 11:56:07,689 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 57418 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-11-22T11:56:07.689648', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.0.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-11-22 11:56:08,742 : INFO : EPOCH 0 - PROGRESS: at 12.74% examples, 428861 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:09,764 : INFO : EPOCH 0 - PROGRESS: at 25.83% examples, 456277 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:10,788 : INFO : EPOCH 0 - PROGRESS: at 40.10% examples, 479426 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:11,823 : INFO : EPOCH 0 - PROGRESS: at 55.29% examples, 492066 words/s, in_qsize 4, out_qsize 2\n",
      "2024-11-22 11:56:12,859 : INFO : EPOCH 0 - PROGRESS: at 70.24% examples, 498295 words/s, in_qsize 6, out_qsize 0\n",
      "2024-11-22 11:56:13,887 : INFO : EPOCH 0 - PROGRESS: at 85.23% examples, 500502 words/s, in_qsize 5, out_qsize 1\n",
      "2024-11-22 11:56:14,770 : INFO : EPOCH 0: training on 4612072 raw words (3616153 effective words) took 7.1s, 511178 effective words/s\n",
      "2024-11-22 11:56:15,786 : INFO : EPOCH 1 - PROGRESS: at 14.21% examples, 497399 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:16,798 : INFO : EPOCH 1 - PROGRESS: at 27.84% examples, 506630 words/s, in_qsize 5, out_qsize 1\n",
      "2024-11-22 11:56:17,834 : INFO : EPOCH 1 - PROGRESS: at 43.03% examples, 515292 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:18,836 : INFO : EPOCH 1 - PROGRESS: at 56.78% examples, 514574 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:19,880 : INFO : EPOCH 1 - PROGRESS: at 71.02% examples, 510099 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:20,898 : INFO : EPOCH 1 - PROGRESS: at 84.52% examples, 502445 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:21,898 : INFO : EPOCH 1 - PROGRESS: at 98.31% examples, 500314 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:21,921 : INFO : EPOCH 1: training on 4612072 raw words (3616486 effective words) took 7.1s, 506243 effective words/s\n",
      "2024-11-22 11:56:22,944 : INFO : EPOCH 2 - PROGRESS: at 12.91% examples, 449151 words/s, in_qsize 5, out_qsize 1\n",
      "2024-11-22 11:56:23,947 : INFO : EPOCH 2 - PROGRESS: at 25.83% examples, 467281 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:24,959 : INFO : EPOCH 2 - PROGRESS: at 38.38% examples, 471189 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:25,964 : INFO : EPOCH 2 - PROGRESS: at 52.99% examples, 481572 words/s, in_qsize 4, out_qsize 2\n",
      "2024-11-22 11:56:26,987 : INFO : EPOCH 2 - PROGRESS: at 67.24% examples, 487311 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:27,998 : INFO : EPOCH 2 - PROGRESS: at 81.66% examples, 491221 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:29,017 : INFO : EPOCH 2 - PROGRESS: at 97.21% examples, 495867 words/s, in_qsize 6, out_qsize 0\n",
      "2024-11-22 11:56:29,117 : INFO : EPOCH 2: training on 4612072 raw words (3616976 effective words) took 7.2s, 503140 effective words/s\n",
      "2024-11-22 11:56:30,166 : INFO : EPOCH 3 - PROGRESS: at 14.44% examples, 497098 words/s, in_qsize 5, out_qsize 1\n",
      "2024-11-22 11:56:31,176 : INFO : EPOCH 3 - PROGRESS: at 28.79% examples, 519819 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:32,185 : INFO : EPOCH 3 - PROGRESS: at 43.58% examples, 521102 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:33,190 : INFO : EPOCH 3 - PROGRESS: at 57.17% examples, 520574 words/s, in_qsize 6, out_qsize 0\n",
      "2024-11-22 11:56:34,196 : INFO : EPOCH 3 - PROGRESS: at 71.89% examples, 521557 words/s, in_qsize 4, out_qsize 2\n",
      "2024-11-22 11:56:35,207 : INFO : EPOCH 3 - PROGRESS: at 86.91% examples, 520030 words/s, in_qsize 4, out_qsize 2\n",
      "2024-11-22 11:56:35,956 : INFO : EPOCH 3: training on 4612072 raw words (3617435 effective words) took 6.8s, 530028 effective words/s\n",
      "2024-11-22 11:56:36,971 : INFO : EPOCH 4 - PROGRESS: at 14.11% examples, 502014 words/s, in_qsize 4, out_qsize 2\n",
      "2024-11-22 11:56:37,983 : INFO : EPOCH 4 - PROGRESS: at 28.20% examples, 516225 words/s, in_qsize 6, out_qsize 0\n",
      "2024-11-22 11:56:38,984 : INFO : EPOCH 4 - PROGRESS: at 43.13% examples, 522679 words/s, in_qsize 6, out_qsize 0\n",
      "2024-11-22 11:56:39,989 : INFO : EPOCH 4 - PROGRESS: at 56.82% examples, 521543 words/s, in_qsize 4, out_qsize 2\n",
      "2024-11-22 11:56:41,001 : INFO : EPOCH 4 - PROGRESS: at 71.86% examples, 524834 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:42,018 : INFO : EPOCH 4 - PROGRESS: at 87.41% examples, 524793 words/s, in_qsize 5, out_qsize 0\n",
      "2024-11-22 11:56:42,756 : INFO : EPOCH 4: training on 4612072 raw words (3616102 effective words) took 6.8s, 532920 effective words/s\n",
      "2024-11-22 11:56:42,756 : INFO : Word2Vec lifecycle event {'msg': 'training on 23060360 raw words (18083152 effective words) took 35.1s, 515676 effective words/s', 'datetime': '2024-11-22T11:56:42.756644', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.0.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-11-22 11:56:42,756 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=57418, vector_size=100, alpha=0.025>', 'datetime': '2024-11-22T11:56:42.756870', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.0.1-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "corpus = Corpus(documents=documents, preprocessor=simple_preprocess)\n",
    "model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['very',\n",
       " 'take',\n",
       " 'things',\n",
       " 'point',\n",
       " 'have_been',\n",
       " 'both',\n",
       " 'made',\n",
       " 'information',\n",
       " 'find',\n",
       " 'windows',\n",
       " 'etc',\n",
       " 'another',\n",
       " 'part',\n",
       " 'without',\n",
       " 'government',\n",
       " 'help',\n",
       " 'apr',\n",
       " 'program',\n",
       " 'however',\n",
       " 'lines_nntp',\n",
       " 'll',\n",
       " 'anyone',\n",
       " 'case',\n",
       " 'through',\n",
       " 'much',\n",
       " 'ax_max',\n",
       " 'fact',\n",
       " 'max_ax',\n",
       " 'data',\n",
       " 'sure',\n",
       " 'too',\n",
       " 'available',\n",
       " 'never',\n",
       " 'anything',\n",
       " 'under',\n",
       " 'number',\n",
       " 'probably',\n",
       " 'file',\n",
       " 've',\n",
       " 'world',\n",
       " 'true',\n",
       " 'better',\n",
       " 'got',\n",
       " 'does_not',\n",
       " 'around',\n",
       " 'game',\n",
       " 'bit',\n",
       " 'again',\n",
       " 'state',\n",
       " 'try']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = model.wv.index_to_key\n",
    "vocab[150:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.7955906 ,  2.0579085 , -0.21899213,  0.57640946,  0.93009514,\n",
       "        0.9880855 , -0.5923485 , -0.85724294, -0.47745353,  0.3002107 ,\n",
       "        0.02649226, -2.3515918 ,  1.6552851 ,  0.6870508 ,  0.15229462,\n",
       "       -2.0009549 ,  1.5693572 , -1.9632825 ,  1.1420659 , -5.4039636 ,\n",
       "        2.2855954 ,  1.1865    ,  2.0600853 , -2.046923  ,  1.0506628 ,\n",
       "        0.06809015, -2.7398582 ,  1.4598666 ,  2.6805813 ,  0.7936425 ,\n",
       "       -0.46178615,  0.44689244, -1.3400604 ,  0.15905245,  1.9218838 ,\n",
       "       -1.0814312 ,  1.2326314 ,  1.7156591 , -1.9361781 ,  1.373386  ,\n",
       "       -0.79441994, -1.5766234 , -0.46121615, -2.5349312 ,  0.5340692 ,\n",
       "       -1.2103965 ,  1.001188  ,  1.4004501 , -1.6127284 , -0.49637172,\n",
       "       -0.32029074, -3.6038728 , -1.3122703 ,  1.2851677 , -2.6535141 ,\n",
       "        0.20665184,  0.642841  , -1.0688782 , -1.3588166 ,  0.10809685,\n",
       "        0.06344327,  3.0690608 , -0.60781074,  1.4185796 ,  1.3655983 ,\n",
       "        0.24590139,  0.4982278 ,  0.91251576, -0.06000046, -0.0489292 ,\n",
       "       -1.9245287 ,  0.5319606 , -0.2595708 ,  0.75831366,  0.36776322,\n",
       "       -0.45746118, -2.1159186 , -1.2090659 , -0.36472437,  0.54746413,\n",
       "        3.6413984 ,  0.03681781,  1.3484794 ,  0.31724536,  1.8761861 ,\n",
       "       -0.0386911 , -0.4290522 ,  1.8470075 ,  0.9482348 , -1.0742908 ,\n",
       "       -0.96263695, -0.20408852, -1.3745085 , -1.7802609 , -0.60759777,\n",
       "        2.0421593 ,  0.96611816, -0.03518327, -2.4831822 ,  1.8229654 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"government\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('citizens', 0.7772632241249084),\n",
       " ('law_enforcement', 0.7499463558197021),\n",
       " ('nsa', 0.7466758489608765),\n",
       " ('administration', 0.7452960014343262),\n",
       " ('govt', 0.734394907951355),\n",
       " ('land', 0.7303112745285034),\n",
       " ('criminal', 0.7282655835151672),\n",
       " ('criminals', 0.727948009967804),\n",
       " ('israel', 0.7217745780944824),\n",
       " ('palestinians', 0.7214918732643127),\n",
       " ('economy', 0.7200716733932495),\n",
       " ('federal_government', 0.7188506126403809),\n",
       " ('property', 0.7177056670188904),\n",
       " ('authorities', 0.7070791125297546),\n",
       " ('illegal', 0.7069562673568726),\n",
       " ('federal', 0.7066277265548706),\n",
       " ('weapons', 0.7043834328651428),\n",
       " ('demand', 0.7030037045478821),\n",
       " ('laws', 0.7028645277023315),\n",
       " ('israeli', 0.7009912729263306)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"government\", topn = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
