
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Text analysis in finance &#8212; Deep Learning and Text Analysis in Finance</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '09_text_analysis_finance';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Decoder models - GPT" href="08_decoder.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="00_welcome.html">
  
  
  
  
  
  
    <p class="title logo__title">Deep Learning and Text Analysis in Finance</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00_welcome.html">
                    Welcome
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_wording_preprocessing.html">Preprocessing text</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_frequency_dictionary_models.html">Frequency based text models</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_neural_networks.html">Neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_word_embeddings.html">Word embeddings with Word2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_document_embeddings.html">Document embeddings with Doc2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_transformer.html">Attention!</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_encoder.html">Encoder models - BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_decoder.html">Decoder models - GPT</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Text analysis in finance</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F09_text_analysis_finance.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/09_text_analysis_finance.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Text analysis in finance</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-tasks-with-stock-market-reactions">Regression tasks with stock market reactions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#event-returns">Event returns</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#excess-returns">Excess returns</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#abnormal-returns">Abnormal returns</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stock-market-reaction">Stock market reaction</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predicting-stock-market-reactions">Predicting stock market reactions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-much-text-information-explains-of-stock-market-reactions">How much text information explains of stock market reactions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stock-market-reactions-and-term-frequencies">Stock market reactions and term frequencies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-is-a-liability-not-a-liability">When is a liability not a liability?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#disclosure-sentiment-machine-learning-vs-dictionary-methods">Disclosure Sentiment: Machine Learning vs Dictionary Methods</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#document-similarity-and-its-usage">Document similarity and its usage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lazy-prices">Lazy Prices</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hedging-climate-change-news">Hedging Climate Change News</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#encoder-models">Encoder models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ask-bert-how-regulatory-disclosure-of-transition-and-physical-climate-risks-affects-the-cds-term-structure">Ask BERT: How Regulatory Disclosure of Transition and Physical Climate Risks Affects the CDS Term Structure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#climate-value-and-values-discovery-in-earnings-calls">Climate Value and Values Discovery in Earnings Calls</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="text-analysis-in-finance">
<h1>Text analysis in finance<a class="headerlink" href="#text-analysis-in-finance" title="Link to this heading">#</a></h1>
<p>So far we mostly discussed different methods how text can be transformed into numerical representations. Starting from frequency based bag-of-word type representations to methods including semantic meaning like Word2Vec and Doc2Vec and finally ending up at language models which capture meaning and context. Given we generate the numerical representation of text, we may use it for different applications which are specific for the domain, e.g., financial markets. In this chapter, we review general concepts which are needed for the application of text models on financial markets. Furthermore, we examine a few academic research papers with versatile applications of text models on financial markets.</p>
<p>We take a look at:</p>
<ul class="simple">
<li><p>the quantification of financial sentiment</p></li>
<li><p>the identification how quickly investors process text information in financial reports</p></li>
<li><p>how financial climate risk is hedged with a textual approach</p></li>
<li><p>how climate talk and climate disclosure can be identified in earning conference calls and annual reports</p></li>
</ul>
<p>From a methodological point of view, the majority of text related tasks which are tackled in these research papers are either regression or classification tasks:</p>
<ul class="simple">
<li><p>Regression tasks usually use text as input and a numerical target variable which is derived from stock market prices</p></li>
<li><p>Classification tasks collect text sequences from financial documents, annotate them and tune a model for automated classification</p></li>
</ul>
<p>If text sequences are manually labeld, usually a genuine and direct link exists between text information and its label. However, labeling is a time-consuming process which can adversely be impacted by subjection. An alternative to manual labeling in the financial domain is to treat market reactions as the label, i.e., if the price of an asset in- or decreases after the release of textual information, the reaction of the market is treated as a label of positive (price increase) or negative (price decrease). This is often used to create target variables for regression tasks and liberates us from manual labeling. However, it comes along with some drawbacks. For instance, the text may include information which is relevant for the assets future development, but, investors do not react towards the information, given they learned about it before from other sources. Or, the information in the text is irrelevant for the assets future, however the market reacts to other developments, e.g., future adverse conditions of the economy. Bottom line, the link between text and market reactions is rather blurry and noisy.</p>
<section id="regression-tasks-with-stock-market-reactions">
<h2>Regression tasks with stock market reactions<a class="headerlink" href="#regression-tasks-with-stock-market-reactions" title="Link to this heading">#</a></h2>
<p>Nevertheless, market reactions are more often used in research due to its easier access and broader availability. So let us take a look how we exactly quantify stock market reactions. As defined in a previous chapter, we define the discrete return of this asset as:</p>
<div class="math notranslate nohighlight">
\[
r_t = \frac{s_{t} - s_{t-1}}{s_{t-1}} = \frac{s_{t}}{s_{t-1}} - 1
\]</div>
<p>given the price of an asset <span class="math notranslate nohighlight">\(s_t\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>. Sometimes, one may use the log-return instead which is defined by:</p>
<div class="math notranslate nohighlight">
\[
z_t = \ln \left( \frac{s_{t}}{s_{t-1}} \right) = \ln \left(1 + r_t\right)
\]</div>
<p>The choice between discrete or log-returns depends on the assumption of discrete vs. continuous trading of assets and a few practical considerations such as discrete returns are additive in the cross-section (at a given point in time) and log-returns are additive over time.</p>
<section id="event-returns">
<h3>Event returns<a class="headerlink" href="#event-returns" title="Link to this heading">#</a></h3>
<p>Given the return of an asset at <span class="math notranslate nohighlight">\(t\)</span> at which textual information is published, one whishes to determine if or how the information is affecting the return and by these means, the market value of an asset. Financial markets are usually very efficient. In this context this means, information which is released by, e.g., an event such as a earning call, is immediately processed by investors. Investors adjust demand and offering prices according to their believes and the effect of the event is immediately reflected in the current price. Thus, to examine if an event affects an asset’s value, it is reasonable to examine the value’s change over the event time period. Let the event occur at time <span class="math notranslate nohighlight">\(t\)</span>, we include the return <span class="math notranslate nohighlight">\(r_t\)</span> which reflects the value change from the last time step before the event <span class="math notranslate nohighlight">\(t-1\)</span> until the event at <span class="math notranslate nohighlight">\(t\)</span>. Furthermore, one adds returns following <span class="math notranslate nohighlight">\(t\)</span>, if the event impacts the value after it occurred. It is common to include only a few more time steps such as one or two. If we include too many time steps afterwards, it gets more likely that the quantified reaction is related to other events following <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>For instance, if Apple is holding a earning call on Wednesday, we would use the return of its stock price from Tuesday until Thursday or Tuesday until Friday to quantify the stock market reaction towards this earning call. To isolate the impact of the event as good as possible, we try to determine the quantify only the unexpected change in the stock price value.</p>
</section>
<section id="excess-returns">
<h3>Excess returns<a class="headerlink" href="#excess-returns" title="Link to this heading">#</a></h3>
<p>What we expect, needs to be defined. The literature either uses excess returns or abnormal returns with this respect. Even though the exact definitions sometimes differ, excess returns are differences of the company’s minus a benchmark <span class="math notranslate nohighlight">\(b\)</span>:</p>
<div class="math notranslate nohighlight">
\[\tilde{r}_{t} = r_{t} - r_{t, b}\]</div>
<p>The benchmark in this context can be a market return from a broad and well diversified market portfolio such as the S&amp;P 1500 or the Euro Stoxx 600. The idea of this excess return is related to the fact that the majority of asset returns are positively correlated, i.e., usually the direction of the stock price movement is similar among assets on the same day. Thus, a positive return may mostly be related to the overall market movement and not to a company specific event. However, if <span class="math notranslate nohighlight">\(\tilde{r}_{t}&gt;0\)</span> signals a positive development in relation to the systematic market movement which may be ascribed to company specific events. Obviously, the same can be said about <span class="math notranslate nohighlight">\(\tilde{r}_{t}&lt;0\)</span> signaling an adverse development in relation to the market movement.</p>
<p>If you take a look in the plot below, you observe the relative stock price development for large US stocks and two major indices (Russell 3000 and S&amp;P 500). We can see that all assets massively loose value in March 2020. This development occurred in the beginning of the Covid crisis which had a systematic impact on all assets. Systematic market movements like these are not related to company specific events and thus, should be filtered first to isolate the relationship between company information and asset price development.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">df_close</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/stock_prices.csv&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">&quot;Date&quot;</span><span class="p">)</span>
<span class="n">df_close</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df_close</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">df_ttr</span> <span class="o">=</span> <span class="n">df_close</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">df_close</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
<span class="n">ttr_plot</span> <span class="o">=</span> <span class="n">df_ttr</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s2">&quot;2020-06-01&quot;</span><span class="p">),</span> <span class="p">:]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Relative asset price development&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">df_returns</span> <span class="o">=</span> <span class="n">df_close</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">df_close</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b3501369411f42228862681382c08c06972534b3e87740226fbc91642916a15c.png" src="_images/b3501369411f42228862681382c08c06972534b3e87740226fbc91642916a15c.png" />
</div>
</div>
</section>
<section id="abnormal-returns">
<h3>Abnormal returns<a class="headerlink" href="#abnormal-returns" title="Link to this heading">#</a></h3>
<p>A even more sophisticated way is to estimate the expected return <span class="math notranslate nohighlight">\(\mu_t\)</span> and subtract it from the realized return. This is called abnormal return <span class="math notranslate nohighlight">\(ar_t\)</span></p>
<div class="math notranslate nohighlight">
\[
ar_t = r_t - \mu_t
\]</div>
<p>Abnormal, because it quantifies the unexpected and by this means abnormal deviation from the expectation. To determine <span class="math notranslate nohighlight">\(\mu_t\)</span>, one can choose among different models. A popular choice is given by factor models. These models regress returns on systematic factors <span class="math notranslate nohighlight">\(\mathbf{f}_t\)</span>:</p>
<div class="math notranslate nohighlight">
\[
r_t = \beta_0 + \boldsymbol{\beta}^T \boldsymbol{f}_t + \epsilon_t
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{f}_t^T = \begin{pmatrix} f_{t, 1} &amp; f_{t, 2} &amp; f_{t, 3} &amp; ...  \end{pmatrix} \)</span> are the observations for a number of systematic factors at <span class="math notranslate nohighlight">\(t\)</span>. Once the model parameters <span class="math notranslate nohighlight">\(\beta_0, \beta_1, \beta_2, ...\)</span> are estimated, the expected value at time <span class="math notranslate nohighlight">\(t\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[
\mu_t = \beta_0 + \boldsymbol{\beta}^T \boldsymbol{f}_t
\]</div>
<p>Thus, given this notation, <span class="math notranslate nohighlight">\(\epsilon_t = ar_t\)</span> which is the part of <span class="math notranslate nohighlight">\(r_t\)</span> that can not be explained by the factors at time <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>For instance, let us assume to use one factor only for stock market companies, we may regress each stock’s return <span class="math notranslate nohighlight">\(r_{t, i}\)</span> on a stock market portfolio return <span class="math notranslate nohighlight">\(r_{t, m}\)</span>. To keep this simple at this stage, let us use a broad market index like the Russell 3000 to approximate the market portfolio. Common approaches in the financial area to capture these systematic effects more appropriately are factor models like the capital asset pricing model, the Fama-French three factor or the Carhardt four factor model.</p>
<p>The output in the cell below is based on a model which regresses the Apple return upon the return of the Russell 3000 index:</p>
<div class="math notranslate nohighlight">
\[
r_{t, AAPL} = \beta_0 + \beta_1 r_{t, R3000} + \epsilon_t
\]</div>
<p>From this regression model, we know that the expected value for Apple, given the realization of the Russell 3000 return is equal to: <span class="math notranslate nohighlight">\(\mu_{t, AAPL | r_{t, R3000}} = \beta_0 + \beta_1 r_{t, R3000}\)</span>; the filtered abnormal return is given by:</p>
<div class="math notranslate nohighlight">
\[
\epsilon_t = r_{t, AAPL} - \beta_0 - \beta_1 r_{t, R3000}
\]</div>
<p>The cell below illustrates Apple’s filtered and unfiltered return in the first half of 2020. We observe, that especially in the financial downturn month of the Covid pandemic (March 2020), Apple’s development has been not as worse as the overall market development.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">start_regression</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s2">&quot;2019-01-01&quot;</span><span class="p">)</span>
<span class="n">end_regression</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s2">&quot;2020-01-01&quot;</span><span class="p">)</span>
<span class="n">end_out_of_time</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s2">&quot;2020-06-01&quot;</span><span class="p">)</span>

<span class="n">ticker</span> <span class="o">=</span> <span class="s2">&quot;AAPL&quot;</span>
<span class="n">portfolio</span> <span class="o">=</span> <span class="s2">&quot;^RUA&quot;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_returns</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">start_regression</span><span class="p">:</span><span class="n">end_regression</span><span class="p">,</span> <span class="n">portfolio</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_returns</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">start_regression</span><span class="p">:</span><span class="n">end_regression</span><span class="p">,</span> <span class="n">ticker</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1">#b0, b1 = lr.intercept_, lr.coef_</span>

<span class="n">X_oot</span> <span class="o">=</span> <span class="n">df_returns</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">end_regression</span><span class="p">:</span><span class="n">end_out_of_time</span><span class="p">,</span> <span class="n">portfolio</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_oot</span> <span class="o">=</span> <span class="n">df_returns</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">end_regression</span><span class="p">:</span><span class="n">end_out_of_time</span><span class="p">,</span> <span class="n">ticker</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">e_oot</span> <span class="o">=</span> <span class="n">y_oot</span> <span class="o">-</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_oot</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">r_t</span> <span class="o">=</span> <span class="n">y_oot</span><span class="p">,</span> <span class="n">e_t</span> <span class="o">=</span> <span class="n">e_oot</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="n">df_returns</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">end_regression</span><span class="p">:</span><span class="n">end_out_of_time</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">results</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;returns (filtered and non-filtered)&quot;</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">results</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;cumulative returns (filtered and non-filtered)&quot;</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/387951d031c1f285a55d7cab133d865222b3314d1f87f57534d5d18769d6715c.png" src="_images/387951d031c1f285a55d7cab133d865222b3314d1f87f57534d5d18769d6715c.png" />
</div>
</div>
</section>
<section id="stock-market-reaction">
<h3>Stock market reaction<a class="headerlink" href="#stock-market-reaction" title="Link to this heading">#</a></h3>
<p>No matter if we use the excess or the abnormal return, to finally quantify the stock market reaction around a event time <span class="math notranslate nohighlight">\(t\)</span>, we define a window size <span class="math notranslate nohighlight">\(w\)</span> and determine the cumulative return. Let <span class="math notranslate nohighlight">\(r_t^{*}\)</span> either represent the excess or abnormal return at time <span class="math notranslate nohighlight">\(t\)</span>, stock market reaction is equal to the cumulative return</p>
<div class="math notranslate nohighlight">
\[
cr_{t, w} = \sum_{t=1}^{w-1} r_t^{*}
\]</div>
<p>Note that a model which is able to predict <span class="math notranslate nohighlight">\(cr_{t, w}\)</span> does not predict the future development after an event. Yet, <span class="math notranslate nohighlight">\(cr_{t, w}\)</span> can be used to gain a deeper understanding how market participants process different types of information. Positive values are interpreted as positive reactions and vice versa.</p>
<p>The cell below shows the filing dates of form 8-K, 10-Q and 10-K filings made by Apple in the first half of 2020. While form 10-Q and 10-K filings refer to regular quarter and annual reports, form 8-K filings are reports which must be filed when major events occur that shareholders should know about.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">apple_filings_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/apple_filings_all.csv&quot;</span><span class="p">)</span>
<span class="n">apple_filings_all</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">apple_filings_all</span><span class="o">.</span><span class="n">filingDate</span><span class="p">)</span>
<span class="n">apple_filings_all</span><span class="o">.</span><span class="n">sort_index</span><span class="p">(</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">apple_filings_all</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">end_regression</span><span class="p">:</span><span class="n">end_out_of_time</span><span class="p">,</span> <span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accessionNumber</th>
      <th>filingDate</th>
      <th>reportDate</th>
      <th>acceptanceDateTime</th>
      <th>act</th>
      <th>form</th>
      <th>fileNumber</th>
      <th>filmNumber</th>
      <th>items</th>
      <th>size</th>
      <th>isXBRL</th>
      <th>isInlineXBRL</th>
      <th>primaryDocument</th>
      <th>primaryDocDescription</th>
      <th>ticker</th>
      <th>cik</th>
    </tr>
    <tr>
      <th>filingDate</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-01-28</th>
      <td>0000320193-20-000008</td>
      <td>2020-01-28</td>
      <td>2020-01-28</td>
      <td>2020-01-28T16:30:40.000Z</td>
      <td>34.0</td>
      <td>8-K</td>
      <td>001-36743</td>
      <td>20554729</td>
      <td>2.02,9.01</td>
      <td>531866</td>
      <td>1</td>
      <td>1</td>
      <td>a8-kq1202012282019.htm</td>
      <td>8-K</td>
      <td>AAPL</td>
      <td>320193</td>
    </tr>
    <tr>
      <th>2020-01-29</th>
      <td>0000320193-20-000010</td>
      <td>2020-01-29</td>
      <td>2019-12-28</td>
      <td>2020-01-28T18:02:44.000Z</td>
      <td>34.0</td>
      <td>10-Q</td>
      <td>001-36743</td>
      <td>20555794</td>
      <td>NaN</td>
      <td>9292589</td>
      <td>1</td>
      <td>1</td>
      <td>a10-qq1202012282019.htm</td>
      <td>10-Q</td>
      <td>AAPL</td>
      <td>320193</td>
    </tr>
    <tr>
      <th>2020-02-18</th>
      <td>0001193125-20-039203</td>
      <td>2020-02-18</td>
      <td>2020-02-17</td>
      <td>2020-02-18T06:24:57.000Z</td>
      <td>34.0</td>
      <td>8-K</td>
      <td>001-36743</td>
      <td>20623292</td>
      <td>7.01,9.01</td>
      <td>310140</td>
      <td>1</td>
      <td>1</td>
      <td>d845033d8k.htm</td>
      <td>FORM 8-K</td>
      <td>AAPL</td>
      <td>320193</td>
    </tr>
    <tr>
      <th>2020-02-27</th>
      <td>0001193125-20-050884</td>
      <td>2020-02-27</td>
      <td>2020-02-26</td>
      <td>2020-02-27T06:14:21.000Z</td>
      <td>34.0</td>
      <td>8-K</td>
      <td>001-36743</td>
      <td>20658351</td>
      <td>5.07</td>
      <td>329670</td>
      <td>1</td>
      <td>1</td>
      <td>d865740d8k.htm</td>
      <td>8-K</td>
      <td>AAPL</td>
      <td>320193</td>
    </tr>
    <tr>
      <th>2020-04-30</th>
      <td>0000320193-20-000050</td>
      <td>2020-04-30</td>
      <td>2020-04-30</td>
      <td>2020-04-30T16:30:41.000Z</td>
      <td>34.0</td>
      <td>8-K</td>
      <td>001-36743</td>
      <td>20836131</td>
      <td>2.02,9.01</td>
      <td>593101</td>
      <td>1</td>
      <td>1</td>
      <td>a8-kq220203282020.htm</td>
      <td>8-K</td>
      <td>AAPL</td>
      <td>320193</td>
    </tr>
    <tr>
      <th>2020-05-01</th>
      <td>0000320193-20-000052</td>
      <td>2020-05-01</td>
      <td>2020-03-28</td>
      <td>2020-04-30T18:03:10.000Z</td>
      <td>34.0</td>
      <td>10-Q</td>
      <td>001-36743</td>
      <td>20837377</td>
      <td>NaN</td>
      <td>10648806</td>
      <td>1</td>
      <td>1</td>
      <td>a10-qq220203282020.htm</td>
      <td>10-Q</td>
      <td>AAPL</td>
      <td>320193</td>
    </tr>
    <tr>
      <th>2020-05-11</th>
      <td>0001193125-20-139112</td>
      <td>2020-05-11</td>
      <td>2020-05-04</td>
      <td>2020-05-11T16:31:15.000Z</td>
      <td>34.0</td>
      <td>8-K</td>
      <td>001-36743</td>
      <td>20865313</td>
      <td>8.01,9.01</td>
      <td>771520</td>
      <td>1</td>
      <td>1</td>
      <td>d926511d8k.htm</td>
      <td>8-K</td>
      <td>AAPL</td>
      <td>320193</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>In the next cell, we take a look at the three day window cumulative abnormal returns of Apple at filing dates. We compare them with the corresponding cumulative returns of Apple and the Russell 3000. We observe mostly positive <span class="math notranslate nohighlight">\(cr_{t,3}\)</span> values at filing dates. The average value of these <span class="math notranslate nohighlight">\(cr_{t, 3}\)</span> at filing dates equals <span class="math notranslate nohighlight">\(0.0287\)</span>, while notably, the average value at days without filings is considerably lower (<span class="math notranslate nohighlight">\(0.0007\)</span>). Furthermore, it is interesting if the filing content impacts <span class="math notranslate nohighlight">\(cr_{t, 3}\)</span> values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">russell_returns</span> <span class="o">=</span> <span class="n">df_returns</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">end_regression</span><span class="p">:</span><span class="n">end_out_of_time</span><span class="p">,</span> <span class="s2">&quot;^RUA&quot;</span><span class="p">]</span>
<span class="n">cumulative_values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1">#cumulative_values.append(results.iloc[i:i+2, :].sum().values)</span>
    <span class="n">cumulative_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">results</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">values</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">russell_returns</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()]))))</span>

<span class="n">cumulative_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cumulative_values</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cr_t&quot;</span><span class="p">,</span> <span class="s2">&quot;car_t&quot;</span><span class="p">,</span> <span class="s2">&quot;cr_t_russell&quot;</span><span class="p">])</span>
<span class="n">event_dates</span> <span class="o">=</span> <span class="n">apple_filings_all</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">end_regression</span><span class="p">:</span><span class="n">end_out_of_time</span><span class="p">,</span> <span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">events</span> <span class="o">=</span> <span class="n">cumulative_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">event_dates</span><span class="p">]</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">apple_filings_all</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">&quot;form&quot;</span><span class="p">],</span> <span class="n">left_index</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">urls</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">base_url</span> <span class="o">=</span> <span class="s2">&quot;https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/&quot;</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">apple_filings_all</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">end_regression</span><span class="p">:</span><span class="n">end_out_of_time</span><span class="p">,</span> <span class="p">]</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">base_url</span> <span class="o">+</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;accessionNumber&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;primaryDocument&quot;</span><span class="p">]</span>
    <span class="n">urls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">no_event_dates</span> <span class="o">=</span> <span class="p">[</span><span class="n">date</span> <span class="k">for</span> <span class="n">date</span> <span class="ow">in</span> <span class="n">cumulative_df</span><span class="o">.</span><span class="n">index</span> <span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">date</span> <span class="ow">in</span> <span class="n">event_dates</span><span class="p">)]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average car_t values around filing days: </span><span class="si">{</span><span class="n">events</span><span class="o">.</span><span class="n">car_t</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">Average car_t values at other days: </span><span class="si">{</span><span class="n">cumulative_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">no_event_dates</span><span class="p">]</span><span class="o">.</span><span class="n">car_t</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">50</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">events</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average car_t values around filing days: 0.0287 
Average car_t values at other days: 0.0007 
--------------------------------------------------
                cr_t     car_t  cr_t_russell  form
filingDate                                        
2020-01-28  0.049222  0.032935      0.008913   8-K
2020-01-29  0.019483  0.014677      0.001874  10-Q
2020-02-18 -0.003828 -0.009502      0.002406   8-K
2020-02-27 -0.065953  0.017331     -0.052132   8-K
2020-04-30  0.004997  0.070515     -0.041240   8-K
2020-05-01 -0.001950  0.036495     -0.024642  10-Q
2020-05-11  0.004307  0.038739     -0.022182   8-K
</pre></div>
</div>
</div>
</div>
<p>So, let us check this manually and read a little of the filings content which can be accessed by the links below.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(cr_{t, 3}\)</span></p></th>
<th class="head"><p>url</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(0.0329\)</span></p></td>
<td><p><a class="reference external" href="https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000032019320000008/a8-kq1202012282019.htm">https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000032019320000008/a8-kq1202012282019.htm</a></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(0.0147\)</span></p></td>
<td><p><a class="reference external" href="https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000032019320000010/a10-qq1202012282019.htm">https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000032019320000010/a10-qq1202012282019.htm</a></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(-0.0095\)</span></p></td>
<td><p><a class="reference external" href="https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000119312520039203/d845033d8k.htm">https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000119312520039203/d845033d8k.htm</a></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(0.0173\)</span></p></td>
<td><p><a class="reference external" href="https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000119312520050884/d865740d8k.htm">https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000119312520050884/d865740d8k.htm</a></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(0.0705\)</span></p></td>
<td><p><a class="reference external" href="https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000032019320000050/a8-kq220203282020.htm">https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000032019320000050/a8-kq220203282020.htm</a></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(0.0365\)</span></p></td>
<td><p><a class="reference external" href="https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000032019320000052/a10-qq220203282020.htm">https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000032019320000052/a10-qq220203282020.htm</a></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(0.0387\)</span></p></td>
<td><p><a class="reference external" href="https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000119312520139112/d926511d8k.htm">https://www.sec.gov/ix?doc=/Archives/edgar/data/0000320193/000119312520139112/d926511d8k.htm</a></p></td>
</tr>
</tbody>
</table>
</div>
<p>The value for <span class="math notranslate nohighlight">\(cr_{t, 3}\)</span> around each filing seems to be strongly related to the content of each filing. This is exactly where text analysis enters the stage. The more accurate the text model is in predicting the <span class="math notranslate nohighlight">\(cr_{t, w}\)</span>, the better it captures the reaction of market participants towards textual information. Once we estimate a model successfully which uses text as input and outputs predictions for the <span class="math notranslate nohighlight">\(cr_{t, w}\)</span> we can use the prediction as an approximation for the financial tone, i.e., if market participants identify the information to have a positive or negative impact on the future market value of an asset. Different approaches for this purpose have been analyzed in the previous literature, so let us take a look at some examples.</p>
</section>
</section>
<section id="predicting-stock-market-reactions">
<h2>Predicting stock market reactions<a class="headerlink" href="#predicting-stock-market-reactions" title="Link to this heading">#</a></h2>
<p>A text based measure for the stock market reaction is a prediction <span class="math notranslate nohighlight">\(\hat{cr}_{t, w}\)</span> for <span class="math notranslate nohighlight">\(cr_{t, w}\)</span>, given text information for an event at time <span class="math notranslate nohighlight">\(t\)</span>. To build such a prediction model, we need:</p>
<ul class="simple">
<li><p>a numerical representation of text</p></li>
<li><p>a trained model which predicts values for <span class="math notranslate nohighlight">\(cr_{t, w}\)</span> as accurate as possible</p></li>
</ul>
<p>With the approaches we learned so far in this book, we already have different options for the transformation of text into numbers:</p>
<ul class="simple">
<li><p>bag-of-words</p></li>
<li><p>tfidf</p></li>
<li><p>dictionary based frequencies</p></li>
<li><p>document embeddings by aggregating Word2Vec vectors of words in a document</p></li>
<li><p>document embeddings by Doc2Vec</p></li>
</ul>
<p>With respect to the prediction model, we already can choose among all supervised learning model which are able to be trained for a regression task. A regression task is a prediction task which utilizes feature realizations <span class="math notranslate nohighlight">\(X\)</span> to predict a real-valued target variable <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>. As the scope of this course is about text modeling, we leave out detailed explanations of supervised learning algorithms, however, e.g., neural networks which have been discussed in a previous chapter would be a reasonable choice.</p>
<p>Let us formalize the prediction model for the application of stock market reactions. Given a corpus of documents <span class="math notranslate nohighlight">\(\lbrace \text{doc}_1, \text{doc}_2, ..., \text{doc}_n \rbrace\)</span>, we use a text model to convert these document to the numerical representation:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X = 
\begin{pmatrix}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \\
\end{pmatrix}
\end{split}\]</div>
<p>Hereby, each row corresponds to one document, thus <span class="math notranslate nohighlight">\(n\)</span> is equal to the number of documents and <span class="math notranslate nohighlight">\(p\)</span> is the dimension which we use to represent every document. For instance in case of a bag-of-word approach, <span class="math notranslate nohighlight">\(p\)</span> is the number of terms in the dictionary or if we use a Doc2Vec model, <span class="math notranslate nohighlight">\(p\)</span> is equal to the embedding dimension.</p>
<p>Given we are able to calculate cumulative (excess or abnormal) returns that correspond to each document, the target variable is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{y} = 
\begin{pmatrix}
cr_{1, t, w} \\
\vdots \\
cr_{n, t, w} \\
\end{pmatrix}
\end{split}\]</div>
<p>The prediction model is denoted by <span class="math notranslate nohighlight">\(f_{\Theta}\)</span> where <span class="math notranslate nohighlight">\(f\)</span> can be a neural network or some other model and <span class="math notranslate nohighlight">\(\Theta\)</span> highlights that the model’s predictions depend on parameters <span class="math notranslate nohighlight">\(\Theta\)</span> which are calibrated such that the model’s predictions are as close as possible to the actual realizations. Usually, the model is trained with a subset of the overall data sample by minimizing the sum of squared deviations and evaluated for data samples which are not used during training.</p>
<p>To evaluate the model for predicting <span class="math notranslate nohighlight">\(cr_{t, w}\)</span>, we introduce a new metric, the <em>naive</em> coefficient of determination <span class="math notranslate nohighlight">\(R_{\text{naive}}^2\)</span>:</p>
<div class="math notranslate nohighlight">
\[
R_{\text{naive}}^2 = 1 - \frac{\sum_{i=1}^n \left(cr_{i, t, w} - \hat{cr}_{i, t, w} \right)^2}{\sum_{i=1}^n cr_{i, t, w}^2}
\]</div>
<p>In general the coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> is defined by:</p>
<div class="math notranslate nohighlight">
\[
R^2 = 1 - \frac{\sum_{i=1}^n \left(y_i - \hat{y}_i \right)^2}{\sum_{i=1}^n \left(y_i - \bar{y} \right)^2}
\]</div>
<p><span class="math notranslate nohighlight">\(R^2\)</span> basically compares two prediction models, one which uses feature information to create predictions <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> and one which predicts the average of all target variable realizations <span class="math notranslate nohighlight">\(\bar{y}\)</span> for each individual realization. The more precise predictions <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> are in comparison to <span class="math notranslate nohighlight">\(\bar{y}\)</span>, the smaller the fraction and the more close <span class="math notranslate nohighlight">\(R^2\)</span> is to <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p>The definition of <span class="math notranslate nohighlight">\(R_{\text{naive}}^2\)</span> implies that we compare the predictions which use text information <span class="math notranslate nohighlight">\(\hat{cr}_{i, t, w}\)</span> with a prediction of <span class="math notranslate nohighlight">\(cr_{i, t, w} = 0\)</span>, i.e., the stock market does not react towards the event at time <span class="math notranslate nohighlight">\(t\)</span>. This means that whenever we evaluate a prediction model and examine <span class="math notranslate nohighlight">\(R_{\text{naive}}^2 &gt; 0\)</span>, we know that the model is able to distinguish at least between positive and negative stock market reactions. The higher <span class="math notranslate nohighlight">\(R_{\text{naive}}^2\)</span>, the better the model is at not only differentiating between positive and negative reactions, but to predict the strength of the stock market reaction.</p>
<p>If should be noted, that individual predictions are not in the center of analyses as described so far. It is rather the average of predictions which should exhibit an increasing monotonic behavior. That means the average of high (low) stock market reactions should also high (low) predictions on average.</p>
</section>
<section id="how-much-text-information-explains-of-stock-market-reactions">
<h2>How much text information explains of stock market reactions<a class="headerlink" href="#how-much-text-information-explains-of-stock-market-reactions" title="Link to this heading">#</a></h2>
<p>Even though the prediction model is trained and delivers good results, the analysis does not end at this point. As long as predictions based on text for <span class="math notranslate nohighlight">\(cr_{t, w}\)</span> are not perfect, the question remains, how much of the stock market reaction can be explained by its text based prediction. To examine this in detail, linear regression analysis is used.</p>
<p>For those not familiar with regression analysis in a statistical and/or economic perspective, let us recap. The linear regression model with multiple (for us <span class="math notranslate nohighlight">\(q\)</span> variables) independent variables:</p>
<div class="math notranslate nohighlight">
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_q + \epsilon =  \boldsymbol{\beta}^T \boldsymbol{x} + \epsilon
\]</div>
<p>with <span class="math notranslate nohighlight">\( \boldsymbol{\beta} = \begin{pmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_q \end{pmatrix}\)</span> and <span class="math notranslate nohighlight">\( \boldsymbol{x} = \begin{pmatrix} 1 \\ x_1 \\ \vdots \\ x_q \end{pmatrix}\)</span></p>
<p>In simple terms, the model predicts the target variable y as a weighted sum of the independent variables <span class="math notranslate nohighlight">\(\left(x_1, x_2, \dots, x_q\right)\)</span>, plus an intercept <span class="math notranslate nohighlight">\(\beta_0\)</span>, and an error term <span class="math notranslate nohighlight">\(\epsilon\)</span> that accounts for randomness or noise.</p>
<p>The model parameters <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> usually are estimated by minimizing the squared deviations between predictions and realizations, thus they are called the ordinary least squares (OLS) estimates. However, in comparison to the pure prediction based point of view from previous and this chapter, the linear regression model is only complete with the residual <span class="math notranslate nohighlight">\(\epsilon\)</span> which is a random variable whose distribution defines the probability distribution for the target variable <span class="math notranslate nohighlight">\(y\)</span>. The multiple linear regression model is based upon a few assumptions. For example, the variance of each <span class="math notranslate nohighlight">\(\epsilon\)</span> and thus for each observation is assumed to be the same (homoscedasticity). Homoscedasticity means that the variability of the residuals (errors) remains constant across all levels of the independent variables. Furthermore, residuals of different observations are assumed to be independent. Under these (and other) assumptions, distributions for estimators of <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> can be derived which are used for statistical tests. Given assumptions are not met for real data sets, standard errors of <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> need to be corrected for proper statistical inference.</p>
<p>Overall, one wishes to identify which of the independent (feature) variables have an impact on the dependent (target) variable that is statistically different from zero. Furthermore, the direction of the impact is of interest. Given any <span class="math notranslate nohighlight">\(\beta_j &gt; 0\)</span> (<span class="math notranslate nohighlight">\(\beta_j &lt; 0\)</span>), we infer a positive (negative) impact between <span class="math notranslate nohighlight">\(x_j\)</span> and <span class="math notranslate nohighlight">\(y\)</span>. Besides the individual impact of each variable, the traditional coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> provides information how much of the target variable’s variation can be explained by feature variables. If we want to compare different sets of features variables, the higher the (adjusted) coefficient of determination, the better the variables are w.r.t. their explanatory power of the target variable. The adjusted <span class="math notranslate nohighlight">\(R^2\)</span> accounts for the number of predictors in the model, ensuring that adding irrelevant variables does not artificially inflate the explanatory power.</p>
<p>The cell below simulates data for a regression analysis which on purpose includes a variable (<span class="math notranslate nohighlight">\(x_3\)</span>) which has no explanatory power for <span class="math notranslate nohighlight">\(y\)</span> and, thus, may be better omitted.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>


<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;x_1&quot;</span><span class="p">,</span> <span class="s2">&quot;x_2&quot;</span><span class="p">,</span> <span class="s2">&quot;x_3&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">corner</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x358703d70&gt;
</pre></div>
</div>
<img alt="_images/150d2a9444f01209963e2da549dd8ac9222d7bb90945451e1f70a62b1e70fecc.png" src="_images/150d2a9444f01209963e2da549dd8ac9222d7bb90945451e1f70a62b1e70fecc.png" />
</div>
</div>
<p>The cell below shows regression results for all combinations which can be chosen for the predictor variables <span class="math notranslate nohighlight">\(x_1, x_2, x_3\)</span>. From the table, we can identify that <span class="math notranslate nohighlight">\(x_1\)</span> alone explains most of the variation of <span class="math notranslate nohighlight">\(y\)</span>. Furthermore, including <span class="math notranslate nohighlight">\(x_2\)</span> increases the level of variation which can be explained. Adding <span class="math notranslate nohighlight">\(x_3\)</span> is not improving the explanatory power. By the signs of the predicted beta-coefficients we further would identify a positive relationship between <span class="math notranslate nohighlight">\(x_1, x_2\)</span> and the target variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pyfixest</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">itertools</span><span class="w"> </span><span class="kn">import</span> <span class="n">combinations</span>

<span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;x_1&quot;</span><span class="p">,</span> <span class="s2">&quot;x_2&quot;</span><span class="p">,</span> <span class="s2">&quot;x_3&quot;</span><span class="p">]</span>
<span class="n">predictor_combinations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">subset</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="n">predictor_combinations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">subset</span><span class="p">))</span>

<span class="n">regressions</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">nbr</span><span class="p">,</span> <span class="n">predictor_combination</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predictor_combinations</span><span class="p">):</span>
    <span class="n">model_string</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;y ~ </span><span class="si">{</span><span class="s1">&#39; + &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">predictor_combination</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">regressions</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;model_</span><span class="si">{</span><span class="n">nbr</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pf</span><span class="o">.</span><span class="n">feols</span><span class="p">(</span>
        <span class="n">model_string</span><span class="p">,</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">df</span>
    <span class="p">)</span>

<span class="n">pf</span><span class="o">.</span><span class="n">etable</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">regressions</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
            <div id="uyoJbe"></div>
            <script type="text/javascript" data-lets-plot-script="library">
                if(!window.letsPlotCallQueue) {
                    window.letsPlotCallQueue = [];
                }; 
                window.letsPlotCall = function(f) {
                    window.letsPlotCallQueue.push(f);
                };
                (function() {
                    var script = document.createElement("script");
                    script.type = "text/javascript";
                    script.src = "https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.5.2/js-package/distr/lets-plot.min.js";
                    script.onload = function() {
                        window.letsPlotCall = function(f) {f();};
                        window.letsPlotCallQueue.forEach(function(f) {f();});
                        window.letsPlotCallQueue = [];
                        
                    };
                    script.onerror = function(event) {
                        window.letsPlotCall = function(f) {};    // noop
                        window.letsPlotCallQueue = [];
                        var div = document.createElement("div");
                        div.style.color = 'darkred';
                        div.textContent = 'Error loading Lets-Plot JS';
                        document.getElementById("uyoJbe").appendChild(div);
                    };
                    var e = document.getElementById("uyoJbe");
                    e.appendChild(script);
                })()
            </script>
            </div><div class="output text_html">
            <div id="IR82BU"></div>
            <script type="text/javascript" data-lets-plot-script="library">
                if(!window.letsPlotCallQueue) {
                    window.letsPlotCallQueue = [];
                }; 
                window.letsPlotCall = function(f) {
                    window.letsPlotCallQueue.push(f);
                };
                (function() {
                    var script = document.createElement("script");
                    script.type = "text/javascript";
                    script.src = "https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.5.2/js-package/distr/lets-plot.min.js";
                    script.onload = function() {
                        window.letsPlotCall = function(f) {f();};
                        window.letsPlotCallQueue.forEach(function(f) {f();});
                        window.letsPlotCallQueue = [];
                        
                    };
                    script.onerror = function(event) {
                        window.letsPlotCall = function(f) {};    // noop
                        window.letsPlotCallQueue = [];
                        var div = document.createElement("div");
                        div.style.color = 'darkred';
                        div.textContent = 'Error loading Lets-Plot JS';
                        document.getElementById("IR82BU").appendChild(div);
                    };
                    var e = document.getElementById("IR82BU");
                    e.appendChild(script);
                })()
            </script>
            </div><div class="output text_html"><div id="mwvxenenxy" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#mwvxenenxy table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#mwvxenenxy thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#mwvxenenxy p { margin: 0; padding: 0; }
 #mwvxenenxy .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: hidden; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #mwvxenenxy .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #mwvxenenxy .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #mwvxenenxy .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #mwvxenenxy .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #mwvxenenxy .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #mwvxenenxy .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: black; border-bottom-style: solid; border-bottom-width: 0.5px; border-bottom-color: black; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #mwvxenenxy .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 0px; border-left-color: white; border-right-style: none; border-right-width: 0px; border-right-color: white; vertical-align: bottom; padding-top: 4px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #mwvxenenxy .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #mwvxenenxy .gt_column_spanner_outer:first-child { padding-left: 0; }
 #mwvxenenxy .gt_column_spanner_outer:last-child { padding-right: 0; }
 #mwvxenenxy .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 0.5px; border-bottom-color: black; vertical-align: bottom; padding-top: 4px; padding-bottom: 4px; overflow-x: hidden; display: inline-block; width: 100%; }
 #mwvxenenxy .gt_spanner_row { border-bottom-style: hidden; }
 #mwvxenenxy .gt_group_heading { padding-top: 0px; padding-bottom: 0px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 0px; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 0.5px; border-top-color: black; border-bottom-style: solid; border-bottom-width: 0.5px; border-bottom-color: black; border-left-style: none; border-left-width: 1px; border-left-color: white; border-right-style: none; border-right-width: 1px; border-right-color: white; vertical-align: middle; text-align: left; }
 #mwvxenenxy .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 0px; font-weight: initial; border-top-style: solid; border-top-width: 0.5px; border-top-color: black; border-bottom-style: solid; border-bottom-width: 0.5px; border-bottom-color: black; vertical-align: middle; }
 #mwvxenenxy .gt_from_md> :first-child { margin-top: 0; }
 #mwvxenenxy .gt_from_md> :last-child { margin-bottom: 0; }
 #mwvxenenxy .gt_row { padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: none; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 0px; border-left-color: white; border-right-style: none; border-right-width: 0px; border-right-color: white; vertical-align: middle; overflow-x: hidden; }
 #mwvxenenxy .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: hidden; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #mwvxenenxy .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #mwvxenenxy .gt_row_group_first td { border-top-width: 0.5px; }
 #mwvxenenxy .gt_row_group_first th { border-top-width: 0.5px; }
 #mwvxenenxy .gt_striped { background-color: rgba(128,128,128,0.05); }
 #mwvxenenxy .gt_table_body { border-top-style: solid; border-top-width: 0.5px; border-top-color: black; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: black; }
 #mwvxenenxy .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #mwvxenenxy .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #mwvxenenxy .gt_left { text-align: left; }
 #mwvxenenxy .gt_center { text-align: center; }
 #mwvxenenxy .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #mwvxenenxy .gt_font_normal { font-weight: normal; }
 #mwvxenenxy .gt_font_bold { font-weight: bold; }
 #mwvxenenxy .gt_font_italic { font-style: italic; }
 #mwvxenenxy .gt_super { font-size: 65%; }
 #mwvxenenxy .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #mwvxenenxy .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>

<tr class="gt_col_headings gt_spanner_row">
  <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="2" colspan="1" scope="col" id=""></th>
  <th class="gt_center gt_columns_top_border gt_column_spanner_outer" rowspan="1" colspan="7" scope="colgroup" id="y">
    <span class="gt_column_spanner">y</span>
  </th>
</tr>
<tr class="gt_col_headings">
  <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="(1)">(1)</th>
  <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="(2)">(2)</th>
  <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="(3)">(3)</th>
  <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="(4)">(4)</th>
  <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="(5)">(5)</th>
  <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="(6)">(6)</th>
  <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="(7)">(7)</th>
</tr>
</thead>
<tbody class="gt_table_body">
  <tr class="gt_group_heading_row">
    <th class="gt_group_heading" colspan="8">coef</th>
  </tr>
  <tr>
    <th class="gt_row gt_left gt_stub">x_1</th>
    <td class="gt_row gt_center">25.789*** <br> (5.762)</td>
    <td class="gt_row gt_center"></td>
    <td class="gt_row gt_center"></td>
    <td class="gt_row gt_center">22.935*** <br> (0.041)</td>
    <td class="gt_row gt_center">25.474*** <br> (5.773)</td>
    <td class="gt_row gt_center"></td>
    <td class="gt_row gt_center">22.933*** <br> (0.041)</td>
  </tr>
  <tr>
    <th class="gt_row gt_left gt_stub">x_2</th>
    <td class="gt_row gt_center"></td>
    <td class="gt_row gt_center">72.930*** <br> (1.450)</td>
    <td class="gt_row gt_center"></td>
    <td class="gt_row gt_center">72.212*** <br> (0.036)</td>
    <td class="gt_row gt_center"></td>
    <td class="gt_row gt_center">72.850*** <br> (1.455)</td>
    <td class="gt_row gt_center">72.210*** <br> (0.036)</td>
  </tr>
  <tr>
    <th class="gt_row gt_left gt_stub">x_3</th>
    <td class="gt_row gt_center"></td>
    <td class="gt_row gt_center"></td>
    <td class="gt_row gt_center">-6.161 <br> (5.351)</td>
    <td class="gt_row gt_center"></td>
    <td class="gt_row gt_center">-4.859 <br> (5.126)</td>
    <td class="gt_row gt_center">-1.168 <br> (1.451)</td>
    <td class="gt_row gt_center">-0.040 <br> (0.036)</td>
  </tr>
  <tr>
    <th class="gt_row gt_left gt_stub">Intercept</th>
    <td class="gt_row gt_center">-10.783* <br> (5.148)</td>
    <td class="gt_row gt_center">1.542 <br> (1.468)</td>
    <td class="gt_row gt_center">-8.901 <br> (5.376)</td>
    <td class="gt_row gt_center">0.003 <br> (0.037)</td>
    <td class="gt_row gt_center">-10.550* <br> (5.155)</td>
    <td class="gt_row gt_center">1.581 <br> (1.470)</td>
    <td class="gt_row gt_center">0.005 <br> (0.037)</td>
  </tr>
  <tr class="gt_group_heading_row">
    <th class="gt_group_heading" colspan="8">stats</th>
  </tr>
  <tr>
    <th class="gt_row gt_left gt_stub">Observations</th>
    <td class="gt_row gt_center">200</td>
    <td class="gt_row gt_center">200</td>
    <td class="gt_row gt_center">200</td>
    <td class="gt_row gt_center">200</td>
    <td class="gt_row gt_center">200</td>
    <td class="gt_row gt_center">200</td>
    <td class="gt_row gt_center">200</td>
  </tr>
  <tr>
    <th class="gt_row gt_left gt_stub">S.E. type</th>
    <td class="gt_row gt_center">iid</td>
    <td class="gt_row gt_center">iid</td>
    <td class="gt_row gt_center">iid</td>
    <td class="gt_row gt_center">iid</td>
    <td class="gt_row gt_center">iid</td>
    <td class="gt_row gt_center">iid</td>
    <td class="gt_row gt_center">iid</td>
  </tr>
  <tr>
    <th class="gt_row gt_left gt_stub">R<sup>2</sup></th>
    <td class="gt_row gt_center">0.092</td>
    <td class="gt_row gt_center">0.927</td>
    <td class="gt_row gt_center">0.007</td>
    <td class="gt_row gt_center">1.000</td>
    <td class="gt_row gt_center">0.096</td>
    <td class="gt_row gt_center">0.928</td>
    <td class="gt_row gt_center">1.000</td>
  </tr>
</tbody>
  <tfoot class="gt_sourcenotes">
  
  <tr>
    <td class="gt_sourcenote" colspan="8">Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:
Coefficient 
 (Std. Error)</td>
  </tr>

</tfoot>

</table>

</div>
        </div></div>
</div>
<p>How do we use this for the analysis of financial stock market reactions towards firm disclosure in textual form? If we only would include the prediction of the stock market reaction we can estimate a regression model of the form:</p>
<div class="math notranslate nohighlight">
\[
cr_{it, w} = \beta_0 + \beta_1 + \hat{cr}_{it, w} + \epsilon_{it}
\]</div>
<p>where the index <span class="math notranslate nohighlight">\(i\)</span> represents companies and <span class="math notranslate nohighlight">\(t\)</span> is the time step of event which occurs at <span class="math notranslate nohighlight">\(t\)</span> for company <span class="math notranslate nohighlight">\(i\)</span>. This means we use the prediction as a explanatory variable. A large value of <span class="math notranslate nohighlight">\(R^2\)</span> would indicate predictions being close to realizations, thus, explaining a large amount of the variation of stock market reactions. However, if further feature variables exist which also are able to explain the variation of <span class="math notranslate nohighlight">\(cr_{t, w}\)</span>, not including them can cause a bias for the estimator of <span class="math notranslate nohighlight">\(\beta_1\)</span>, thus, false quantification of its impact. This is why we should further add other feature variables to the regression which may be related to <span class="math notranslate nohighlight">\(cr_{t, w}\)</span>. From the literature, it is known that, e.g., the size of a company or its book-to-market value are related to the returns of a company. This is why they also might be related to cumulative excess or abnormal returns. Thus, the regression usually also includes further variable which are called control variables <span class="math notranslate nohighlight">\(C\)</span>:</p>
<div class="math notranslate nohighlight">
\[
cr_{it, w} = \beta_0 + \beta_1 \hat{cr}_{it, w} + \mathbf{\gamma} C_{it} + \epsilon_{it}
\]</div>
<p>Without going to much into the details, for econometric reasons we further often include a constant parameter which is different for every company and a specific time period <span class="math notranslate nohighlight">\(t'\)</span>, e.g., a quarter or year. The regression becomes:</p>
<div class="math notranslate nohighlight">
\[
cr_{it, w} = \beta_i + \beta_{t'} + \beta_1 \hat{cr}_{it, w} + \mathbf{\gamma}^T C_{it} + \epsilon_{it}
\]</div>
<p>Even though it looks more complicated, the interpretation in terms of adjusted <span class="math notranslate nohighlight">\(R^2\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> coefficients remain as before.</p>
</section>
<section id="stock-market-reactions-and-term-frequencies">
<h2>Stock market reactions and term frequencies<a class="headerlink" href="#stock-market-reactions-and-term-frequencies" title="Link to this heading">#</a></h2>
<p>Two popular papers which investigate the relation between the sentiment of company reports and earning call transcripts and stock market reactions are by <a class="reference external" href="https://www.uts.edu.au/sites/default/files/ADG_Cons2015_Loughran%20McDonald%20JE%202011.pdf">Loughran and McDonald (2011)</a> and <a class="reference external" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3845780">Frankel et. al (2022)</a>.</p>
<section id="when-is-a-liability-not-a-liability">
<h3>When is a liability not a liability?<a class="headerlink" href="#when-is-a-liability-not-a-liability" title="Link to this heading">#</a></h3>
<p>Loughran and MacDonald (2011) do not create predictions for financial sentiment, however, as described in the former chapters, they define a finance specific dictionary and count the frequency of negative tone in form 10-K annual filings of stock market listed companies. This variable is called Fin-Neg in the table of their paper below. The ability of this variable to explain the variation the cumulative excess return over the annual report’s disclosure is compared to the negative tone measured by words from a more common dictionary that is not finance specific (H4N-Inf).</p>
<p>If you take a look in the table below, you also see further variables which are included as control variables. Furthermore the Average <span class="math notranslate nohighlight">\(R^2\)</span> is the average of <span class="math notranslate nohighlight">\(R^2\)</span> values over multiple regression from different quarters. Also the displayed coefficients are averages of estimated coefficients over all quarters. Values in curly brackets are t-statistics which can be used for statistical inference. Under normality of the t-value, absolute values exceeding <span class="math notranslate nohighlight">\(1.645\)</span> are the ones which would reject the null hypothesis of no impact under common significance levels. Proportional Weights are the frequencies of negative words in annual reports, the two columns to the right exhibit results when negative terms are weighted by their inverse document frequencies before aggregation.</p>
<p>If we take a look at the two columns referring to the proportional weights, we observe a negative impact of negative tone on stock market reactions. The interesting take away is that the impact of the variable using the finance specific dictionary is statistically different from zero, while the one using the common dictionary is not. At the same time, variables of both dictionaries exhibit a negative impact on stock market reactions that is statistically different from zero. Thus, investors seem to react towards textual information of annual reports. Nevertheless, this result should not be overstated as the average value of <span class="math notranslate nohighlight">\(R^2\)</span> scores is relatively small. This indicates that only little of the actual variation of stock market reactions can be explained by the control and text variables. This is rather common in the financial domain which is largely exposed to randomness and lacks of strong deterministic relationships between firm variables and stock market developments.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;lmcd_results_table.png&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">700</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/7e7f43c5c4b2c06cb7893a6ae197ab2b93faeb50cdd6ea17224f82669dd13d00.png"><img alt="_images/7e7f43c5c4b2c06cb7893a6ae197ab2b93faeb50cdd6ea17224f82669dd13d00.png" src="_images/7e7f43c5c4b2c06cb7893a6ae197ab2b93faeb50cdd6ea17224f82669dd13d00.png" style="width: 700px;" /></a>
</div>
</div>
</section>
<section id="disclosure-sentiment-machine-learning-vs-dictionary-methods">
<h3>Disclosure Sentiment: Machine Learning vs Dictionary Methods<a class="headerlink" href="#disclosure-sentiment-machine-learning-vs-dictionary-methods" title="Link to this heading">#</a></h3>
<p>The study from above is repeated by Frankel et. al (2022) using data up to more recent time periods. They find that the impact of negative tone measured by the dictionary of Loughran and MacDonald seems to vanish. Three variables are examined:</p>
<ul class="simple">
<li><p>Tone: number of positive words minus negative words divided by the number of positive and negative words</p></li>
<li><p>Pos Tone: frequency of positive words</p></li>
<li><p>Neg Tone: frequency of negative words</p></li>
</ul>
<p>Each of them do not exhibit a considerable impact from a statistical impact for the larger time period between 1996 and 2019. However, the authors show two more things in their paper:</p>
<ol class="arabic simple">
<li><p>Machine learning based sentiment predictions as described in this chapter exhibit a significant impact to explain the variation of stock market reactions.</p></li>
<li><p>By far more variation can be explained for cumulative abnormal returns surrounding earning conference calls in comparison to annual reports.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;frankel_1.png&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">700</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/d2c78591d914d70bbb913deb990ad8a88e96d0fc6a30bf455b0dfbe9e147f8b9.png"><img alt="_images/d2c78591d914d70bbb913deb990ad8a88e96d0fc6a30bf455b0dfbe9e147f8b9.png" src="_images/d2c78591d914d70bbb913deb990ad8a88e96d0fc6a30bf455b0dfbe9e147f8b9.png" style="width: 700px;" /></a>
</div>
</div>
<p>In their paper, they compare different machine learning models, but random forests which are trained on uni- and bigram counts of documents exhibit the best prediction performance. The table below contrasts the impact of random forest sentiment prediction (RF) to the Loughran and MacDonald tone (LM) and the one derived by the common Harvard dictionary (HARV). Each of the variables has a positive impact on the stock market reaction around a earning call, however as can be seen by the adjusted <span class="math notranslate nohighlight">\(R^2\)</span>, the random forest sentiment variable is at least twice as high as for the other variables. This indicates that the random forest prediction is capturing the financial sentiment in a more precise manner.</p>
<p>Comparing the <span class="math notranslate nohighlight">\(R^2\)</span> levels of the table above (10-K) and the one below (earning calls), demonstrates that much more of the stock market reaction to earning calls is explainable by control variables and the text variable. A reason for this may lie in the nature of both events. Earning calls are usually before annual or quarter reports are released. Furthermore, they are less prepared and may allow analysts and investors to elicit more relevant information from firm representatives. Thus, information released in 10-K reports are known before and included in asset prices before the event occurs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;frankel_2.png&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">700</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/7b23ea4b6506a5f650e20044642b6e1874eaa5f79d25c7a5c5a43245c3515a3b.png"><img alt="_images/7b23ea4b6506a5f650e20044642b6e1874eaa5f79d25c7a5c5a43245c3515a3b.png" src="_images/7b23ea4b6506a5f650e20044642b6e1874eaa5f79d25c7a5c5a43245c3515a3b.png" style="width: 700px;" /></a>
</div>
</div>
</section>
</section>
<section id="document-similarity-and-its-usage">
<h2>Document similarity and its usage<a class="headerlink" href="#document-similarity-and-its-usage" title="Link to this heading">#</a></h2>
<p>The papers by Loughran and MacDonald (2011) as well as Frankel et al. (2022) rely upon term frequencies and directly model their relation to financial market sentiment. Besides, we also can find useful document similarity based approaches in the financial literature. Two very different but interesting application are presented by <a class="reference external" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1658471">Cohen et. al (2020)</a> and <a class="reference external" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3317570">Engle et. al (2020)</a>.</p>
<section id="lazy-prices">
<h3>Lazy Prices<a class="headerlink" href="#lazy-prices" title="Link to this heading">#</a></h3>
<p>In “Lazy Prices”, Cohen et al. (2020) explore the predictive power of linguistic changes in financial filings (10-K and 10-Q reports) on stock returns and firm performance. They rely on textual similarity measures, comparing term frequencies across different filing periods to identify meaningful changes in language and structure. The primary focus is on how subtle modifications in corporate disclosures signal shifts in company fundamentals, which investors often overlook. By employing these textual metrics, the paper quantifies “non-obvious” updates in filings and connects these changes to market inefficiencies, such as delayed investor reactions.</p>
<p>This approach leverages term frequency to assess semantic stability or drift, identifying linguistic updates as proxies for evolving firm-specific risks or opportunities. The authors use the insights to argue that markets fail to price in all relevant information promptly, creating opportunities for excess returns.</p>
<p>More concrete, the authors holistically analyze a universe of US companies. Text documents are annual 10-K and quarter 10-Q reports. To quantify the similarity of firm reports, they use use four different metrics:</p>
<ul class="simple">
<li><p>Cosine similarity</p></li>
<li><p>Jaccard similarity</p></li>
<li><p>Minimum edit distance</p></li>
<li><p>Simple similarity</p></li>
</ul>
<p>All measures are determined between two documents. For instance, cosine similarity uses the set of all terms which occur in both documents, determines their frequencies per document and calculates the cosine similarity between those vectors. Given the two documents:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D_1\)</span>: financial data analytics</p></li>
<li><p><span class="math notranslate nohighlight">\(D_2\)</span>: financial data analysis</p></li>
</ul>
<p>we collect the dictionary by: [financial, data, analytics, analysis]</p>
<p>The term frequency vectors are:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(TF_1\)</span>: [1, 1, 1, 0]</p></li>
<li><p><span class="math notranslate nohighlight">\(TF_1\)</span>: [1, 1, 0, 1]</p></li>
</ul>
<p>The dot-product is: <span class="math notranslate nohighlight">\((1 \cdot 1) + (1 \cdot 1) + (1 \cdot 0) + (0 \cdot 1) = 2\)</span></p>
<p>The length of each vector is: <span class="math notranslate nohighlight">\(\sqrt{3}\)</span></p>
<p>This would result in the cosine similarity:;</p>
<div class="math notranslate nohighlight">
\[
d_{cosine} = \frac{2}{\sqrt{3} \sqrt{3}} = \frac{2}{3} \approx 0.667 
\]</div>
<p>The highest effect sizes are given for the Jaccard similarity in the paper, so let us also take a look how it is defined. The Jaccard similarity compares the documents based on the overlap of terms in their sets.</p>
<p>First, we need to define the sets of terms in both documents:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D_1\)</span>: (financial, data, analytics)</p></li>
<li><p><span class="math notranslate nohighlight">\(D_2\)</span>: (financial, data, analysis)</p></li>
</ul>
<p>Next, we determine the intersection and union:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D_1 \cap D_2 \)</span>: (financial, data)</p></li>
<li><p><span class="math notranslate nohighlight">\(D_1 \cup D_2 \)</span>: (financial, data, analytics, analysis)</p></li>
</ul>
<p>Finally, Jaccard similarity is the ratio for number of elements in the intersection and the union:</p>
<div class="math notranslate nohighlight">
\[
d_{jaccard} = \frac{|D_1 \cap D_2|}{|D_1 \cup D_2|} = \frac{2}{4} = 0.5
\]</div>
<p>In their paper, they always compare a report with its counterpart from the previous year, e.g., report for the first quarter in 2023 with the one in the first quarter in 2024. The analysis is done with data between 1995 and 2014. On the firm level, they conduct monthly regressions which regress the next month’s return upon the similarity measures and control variables. See the table from their paper below. Each of the similarity measures has a positive sign and is statistically different from zero (at a significance level of at 5%). This implies that companies with lower similarity do have a lower expected return. From a asset pricing perspective, this means investors demand a premium for companies that do not change their reports. This would only make sense if changes are mostly associated with positive company developments and a decrease in company risk.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;lazy_prices_regression.png&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">800</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/61aa7d6fd352fb9d5e66e84a2c2620c46d2a16bf83262e202211b5744c6003f9.png"><img alt="_images/61aa7d6fd352fb9d5e66e84a2c2620c46d2a16bf83262e202211b5744c6003f9.png" src="_images/61aa7d6fd352fb9d5e66e84a2c2620c46d2a16bf83262e202211b5744c6003f9.png" style="width: 800px;" /></a>
</div>
</div>
<p>However, the opposite seems to be true as they conduct another regression to get further insights of document changes. The regression table below regresses one of their similarity metrics on sentiment, uncertainty, litigious and CEO references in document changes. The results show that similarities decrease if more negative, litigious and uncertainty words are used or if the change is announcing the change of the company’s CEO or CFO. This creates a puzzling result as changes in the document seem to be related to aspects creating uncertainty and risk of the company. At the same time, investors want to be less compensated when holding companies with higher document changes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;lazy_prices_regression_2.png&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">600</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/79cc35e7191cff757ed3619ed7613d228f076811bc3e9a84f8a55ee45ff60a5f.png"><img alt="_images/79cc35e7191cff757ed3619ed7613d228f076811bc3e9a84f8a55ee45ff60a5f.png" src="_images/79cc35e7191cff757ed3619ed7613d228f076811bc3e9a84f8a55ee45ff60a5f.png" style="width: 600px;" /></a>
</div>
</div>
<p>The only explanation which makes this result plausible is, that investors fail to directly include the information of the document changes at the time they are revealed. This seems to be true and revealed by a portfolio analysis in the paper. Based on the document similarity, they build two portfolios. One containing companies with the least document changes and one with the highest document changes. Over time portfolio components are added and deleted according to their current document similarity. To extract the difference between the two portfolios we take a look at the difference in returns of the portfolio with the least and the most changes. This is from the paper’s appendix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;lazy_prices_pf_returns.png&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">800</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/27e50a48706d634bc1e4fbfd6b8f6fc887dc989c0ba8d3304b4a8dd9dcd88f97.png"><img alt="_images/27e50a48706d634bc1e4fbfd6b8f6fc887dc989c0ba8d3304b4a8dd9dcd88f97.png" src="_images/27e50a48706d634bc1e4fbfd6b8f6fc887dc989c0ba8d3304b4a8dd9dcd88f97.png" style="width: 800px;" /></a>
</div>
</div>
<p>As we can see the portfolio of least changers outperforms the most changers in most of the months, predominately in the early 2000s where the dot-com crisis took place. This is true when controlling for risk factors. To identify the origin of the outperformance, the figure below exhibits averages of cumulative abnormal returns after report disclosure. It gets clear that companies with high changes in their company reports experience a decrease in market value over time, not at the event of information disclosure, but, months after it. This is quite uncommon for efficient markets which immediately process information into the companies’ stock market prices.</p>
<p>Thus, the paper reveals that investors seem to be unable to detect information which is relevant for the companies’ value. Note that this is done by a rather simply method of using term frequencies and cosine similarity.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;lazy_prices_pf_returns2.png&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">700</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/aca76e929975fec63d8fbf66a3e8a41d8d29f3cd0f68d3de49c9c0f91bfaae86.png"><img alt="_images/aca76e929975fec63d8fbf66a3e8a41d8d29f3cd0f68d3de49c9c0f91bfaae86.png" src="_images/aca76e929975fec63d8fbf66a3e8a41d8d29f3cd0f68d3de49c9c0f91bfaae86.png" style="width: 700px;" /></a>
</div>
</div>
</section>
<section id="hedging-climate-change-news">
<h3>Hedging Climate Change News<a class="headerlink" href="#hedging-climate-change-news" title="Link to this heading">#</a></h3>
<p>The paper by Engle et al. (2020), Hedging Climate Change News, addresses the growing need to manage climate-related risks in financial markets. Climate risk is increasingly recognized as a critical factor affecting global economies due to its long-term, systemic, and non-diversifiable nature. These risks stem from both physical impacts (e.g., extreme weather events, rising sea levels) and transitional challenges (e.g., regulatory changes, shifts to low-carbon economies).</p>
<p>As investors and companies seek to mitigate these uncertainties, traditional hedging tools like futures or insurance contracts face limitations. For example, the long-term horizon and correlated nature of climate risks make it difficult for counterparties to credibly ensure payouts during a widespread crisis. In this context, dynamically constructed hedge portfolios using publicly traded assets, as proposed by Engle et al. (2020), are critical. These portfolios offer a feasible approach to offset the financial impacts of climate risks by aligning market exposures with innovations in climate news, a key driver of investor sentiment and decision-making.</p>
<p>More concrete, in their paper, they use term frequency analysis to construct indices that capture the intensity and sentiment of climate change coverage in media outlets. They develop the WSJ Climate Change News Index, which measures the prevalence of climate-related terms in The Wall Street Journal. This index is built using textual corpora, where climate-related term frequencies are weighted using methods like Term Frequency-Inverse Document Frequency (TF-IDF) and cosine similarity to authoritative climate change texts.</p>
<p>The objective here is to capture “innovations” in climate news—unexpected shifts in media coverage that might influence investor perceptions of climate risks. These innovations serve as inputs for constructing hedge portfolios that aim to mitigate the financial impact of climate-related risks. Thus, term frequency is not merely used to identify changes in text but to model a market-relevant risk factor.</p>
<p>Let us quickly take a look how, the climate change index is determined with help of a minimum example. In their paper, they collect documents whose emphasis lies on climate change (e.g., IPCC reports) and news articles of the wall street journal.</p>
<ul class="simple">
<li><p>Climate documents:</p>
<ul>
<li><p>Document 1: “greenhouse gas emissions increase global warming”</p></li>
<li><p>Document 2: “renewable energies help to reduce greenhouse gas emissions”</p></li>
</ul>
</li>
<li><p>News articles:</p>
<ul>
<li><p>Article 1: “greenhouse gas emissions are a major driver of future economic losses”</p></li>
<li><p>Article 2: “the markets go up these days”</p></li>
</ul>
</li>
</ul>
<p>In the original paper, TF-IDF vectors for every document are generated. Hereby, there is only one climate document which includes the term frequencies from all climate documents. Furthermore, a newspaper document is the aggregate of all news articles for a single day. Thus, the frequencies of all articles within a day are used for determining the news TF-IDF vectors.</p>
<p>In our example below, we have two articles from climate reports (d1, d2) and news articles from two days (a1, a2). Furthermore, we are going to ignore inverse document frequencies for our example. In a first step we create the unique set of terms and remove stop words.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d1</span> <span class="o">=</span> <span class="s2">&quot;greenhouse gas emissions increase global warming&quot;</span>
<span class="n">d2</span> <span class="o">=</span> <span class="s2">&quot;renewable energies help to reduce greenhouse gas emissions&quot;</span>
<span class="n">a1</span> <span class="o">=</span> <span class="s2">&quot;greenhouse gas emissions are a major driver of future economic losses&quot;</span>
<span class="n">a2</span> <span class="o">=</span> <span class="s2">&quot;the markets go up these days&quot;</span>

<span class="n">terms</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">]:</span>
    <span class="n">terms</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">terms</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">terms</span><span class="p">))</span>

<span class="n">stop_words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;the&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;are&quot;</span><span class="p">,</span> <span class="s2">&quot;of&quot;</span><span class="p">,</span> <span class="s2">&quot;to&quot;</span><span class="p">]</span>
<span class="n">terms</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">)]</span>
<span class="n">terms</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;driver&#39;,
 &#39;economic&#39;,
 &#39;go&#39;,
 &#39;gas&#39;,
 &#39;up&#39;,
 &#39;these&#39;,
 &#39;emissions&#39;,
 &#39;warming&#39;,
 &#39;greenhouse&#39;,
 &#39;major&#39;,
 &#39;reduce&#39;,
 &#39;losses&#39;,
 &#39;global&#39;,
 &#39;future&#39;,
 &#39;renewable&#39;,
 &#39;help&#39;,
 &#39;days&#39;,
 &#39;energies&#39;,
 &#39;markets&#39;,
 &#39;increase&#39;]
</pre></div>
</div>
</div>
</div>
<p>Next, we determine the term frequencies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="k">def</span><span class="w"> </span><span class="nf">term_frequencies</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">terms</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">terms</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">counts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">counts</span>

<span class="n">tfs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="n">terms</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">]):</span>
    <span class="n">tfs</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">term_frequencies</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

<span class="n">tfs</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;d1&quot;</span><span class="p">,</span> <span class="s2">&quot;d2&quot;</span><span class="p">,</span> <span class="s2">&quot;a1&quot;</span><span class="p">,</span> <span class="s2">&quot;a2&quot;</span><span class="p">]</span>
<span class="n">tfs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>driver</th>
      <th>economic</th>
      <th>go</th>
      <th>gas</th>
      <th>up</th>
      <th>these</th>
      <th>emissions</th>
      <th>warming</th>
      <th>greenhouse</th>
      <th>major</th>
      <th>reduce</th>
      <th>losses</th>
      <th>global</th>
      <th>future</th>
      <th>renewable</th>
      <th>help</th>
      <th>days</th>
      <th>energies</th>
      <th>markets</th>
      <th>increase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>d1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>d2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>a1</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>a2</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Afterwards, we aggregate term frequencies over all climate reports.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">climate_vector</span> <span class="o">=</span> <span class="n">tfs</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s2">&quot;d1&quot;</span><span class="p">,</span> <span class="s2">&quot;d2&quot;</span><span class="p">],</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s2">&quot;climate&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
<span class="n">climate_vector</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>driver</th>
      <th>economic</th>
      <th>go</th>
      <th>gas</th>
      <th>up</th>
      <th>these</th>
      <th>emissions</th>
      <th>warming</th>
      <th>greenhouse</th>
      <th>major</th>
      <th>reduce</th>
      <th>losses</th>
      <th>global</th>
      <th>future</th>
      <th>renewable</th>
      <th>help</th>
      <th>days</th>
      <th>energies</th>
      <th>markets</th>
      <th>increase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>climate</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>If we calculate the cosine similarity, we determine the dot-product of two vectors and normalize them by their length. The dot-product is the sum of elementwise multiplication. Thus, for our example, if we take a look at the elementwise multiplication for the climate frequency and the news vectors, we could observe overlapping words of climate reports and news of article 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">climate_vector</span> <span class="o">*</span> <span class="n">tfs</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;a1&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>driver</th>
      <th>economic</th>
      <th>go</th>
      <th>gas</th>
      <th>up</th>
      <th>these</th>
      <th>emissions</th>
      <th>warming</th>
      <th>greenhouse</th>
      <th>major</th>
      <th>reduce</th>
      <th>losses</th>
      <th>global</th>
      <th>future</th>
      <th>renewable</th>
      <th>help</th>
      <th>days</th>
      <th>energies</th>
      <th>markets</th>
      <th>increase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>climate</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>However, we could not identify any similarity of climate reports and the second article.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">climate_vector</span> <span class="o">*</span> <span class="n">tfs</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;a2&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>driver</th>
      <th>economic</th>
      <th>go</th>
      <th>gas</th>
      <th>up</th>
      <th>these</th>
      <th>emissions</th>
      <th>warming</th>
      <th>greenhouse</th>
      <th>major</th>
      <th>reduce</th>
      <th>losses</th>
      <th>global</th>
      <th>future</th>
      <th>renewable</th>
      <th>help</th>
      <th>days</th>
      <th>energies</th>
      <th>markets</th>
      <th>increase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>climate</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Accordingly, we could identify the day of article 1 as a day with climate talk in the news and the day of article 2 where climate talk has not been relevant in the news. In broader terms, the paper’s approach focuses on identifying days when news articles contain language commonly associated with discussions about the consequences of climate change. The underlying assumption is that news coverage of climate-related topics often conveys information that heightens companies’ exposure to climate risks.</p>
<p>In the paper of Engle et. al (2020), this is done with daily Wall Street Journal news and the climate vector is build upon a large collection of documents and glossaries about climate change. To reveal the changes in climate risk, the index itself is created as changes (between subsequent days) of daily cosine similarities between the news articles and the climate vector. See the figure below from their paper which shows the development of the climate change index between 1985 and 2017.</p>
<p>The goal of their paper is to create a portfolio whose value increases if the climate change index increases to hedge against an in crease in climate risk from the companies’ perspective. This is where the actual “work” of the paper starts. However, this extract is the one using language modeling which is why we end the presentation here and leave interested readers to the original research article.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;engle_hedging.png&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">800</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/6ef035692accbc6b2b9177e26a893670831aabc68303fbba2f48a9e9bf7cec9f.png"><img alt="_images/6ef035692accbc6b2b9177e26a893670831aabc68303fbba2f48a9e9bf7cec9f.png" src="_images/6ef035692accbc6b2b9177e26a893670831aabc68303fbba2f48a9e9bf7cec9f.png" style="width: 800px;" /></a>
</div>
</div>
</section>
</section>
<section id="encoder-models">
<h2>Encoder models<a class="headerlink" href="#encoder-models" title="Link to this heading">#</a></h2>
<p>We already examined the FinBERT paper and its applications in the paper by <a class="reference external" href="https://onlinelibrary.wiley.com/doi/full/10.1111/1911-3846.12832">Huang and Yiang (2022)</a>. Besides, most of financial research paper use encoder models like this to detect sequences related to a topic in longer financial reports. The appearance of such sequences is then used for varying company analyses.</p>
<section id="ask-bert-how-regulatory-disclosure-of-transition-and-physical-climate-risks-affects-the-cds-term-structure">
<h3>Ask BERT: How Regulatory Disclosure of Transition and Physical Climate Risks Affects the CDS Term Structure<a class="headerlink" href="#ask-bert-how-regulatory-disclosure-of-transition-and-physical-climate-risks-affects-the-cds-term-structure" title="Link to this heading">#</a></h3>
<p>Popular applications are the identification of climate talk in company reports and earning calls. Two examples are presented by <a class="reference external" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3616324">Kölbel et. al (2022)</a> and <a class="reference external" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4596668">Sautner et. al (2024)</a>. The paper by Kölbel et. al finetunes the general purpose BERT model to identify sentences related to climate disclosure in 10-K annual firm reports. They, distinguish between the categories “general”, “physical”, “transition”. The latter two are both related to climate risk.</p>
<p>Physical climate risk refers to the direct impacts of climate change on natural and human systems, such as extreme weather events like hurricanes and floods or long-term changes like rising sea levels and increasing temperatures. These risks primarily affect physical assets, ecosystems, and human health.</p>
<p>On the other hand, transition climate risk arises from the societal and economic adjustments required to move toward a low-carbon economy. This includes risks related to changing government policies, shifts in market dynamics, technological advancements, and reputational pressures. While physical risks deal with the tangible effects of climate change, transition risks are rooted in the challenges and disruptions associated with mitigating those effects and adapting to a sustainable future.</p>
<p>Since 2010, the securities and exchange commission (SEC) in the US provided guidelines that four items  of form K reports:</p>
<ul class="simple">
<li><p>description of the business</p></li>
<li><p>legal proceedings</p></li>
<li><p>risk factors</p></li>
<li><p>management’s discussion and analysis of financial condition and results of operations</p></li>
</ul>
<p>may require disclosure related to climate change. Kölbel et. al (2022) use the finetuned BERT model to identify the fraction of climate related sentences in Item 1A of 10-K reports as this item is related to declaring risk factors for the business of a company.</p>
<p>In their analysis, they use this feature to examine if climate disclosure has explanatory for the creditworthiness of a company. The latter is measured by changes of credit default swap (CDS) spreads. The most important findings of the analysis are that higher levels of transition risk reduces creditworthiness by increasing CDS spreads, while the impact of physical disclosure levels are reversed. The former inducing higher company risk, the latter reduces uncertainty leading to higher levels of creditworthiness.</p>
</section>
<section id="climate-value-and-values-discovery-in-earnings-calls">
<h3>Climate Value and Values Discovery in Earnings Calls<a class="headerlink" href="#climate-value-and-values-discovery-in-earnings-calls" title="Link to this heading">#</a></h3>
<p>The paper explores how financial analysts address climate change concerns in corporate earnings calls, focusing on both financial (value) and non-financial (values) aspects. To identify climate related questions by analysis, they finetune the FinBERT model by Huang and Yiang (2022) using 2,400 sentences from earning call transcripts.</p>
<p>Key findings include that climate-related questions are increasingly frequent and tailored to specific industries and periods of relevance. Value-related discussions, which emphasize financial impacts like costs and investments, have gained relative importance over time, especially since 2018. In contrast, values-related inquiries address moral and regulatory concerns. Analysts’ climate discussions influence stock trading volumes, reflecting investor disagreement on interpreting climate information.</p>
<p>Interestingly, the paper finds that analysts’ interest in climate change is not an innate trait but a dynamic response to market and situational factors. Climate-focused analysts benefit in their careers, with value-centric discussions offering stronger predictive power for promotions and job mobility compared to values-centric ones. This study sheds light on the evolving role of analysts in integrating climate change into financial and ethical decision-making.</p>
</section>
</section>
<section id="id1">
<h2><a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="08_decoder.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Decoder models - GPT</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-tasks-with-stock-market-reactions">Regression tasks with stock market reactions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#event-returns">Event returns</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#excess-returns">Excess returns</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#abnormal-returns">Abnormal returns</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stock-market-reaction">Stock market reaction</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predicting-stock-market-reactions">Predicting stock market reactions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-much-text-information-explains-of-stock-market-reactions">How much text information explains of stock market reactions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stock-market-reactions-and-term-frequencies">Stock market reactions and term frequencies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-is-a-liability-not-a-liability">When is a liability not a liability?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#disclosure-sentiment-machine-learning-vs-dictionary-methods">Disclosure Sentiment: Machine Learning vs Dictionary Methods</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#document-similarity-and-its-usage">Document similarity and its usage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lazy-prices">Lazy Prices</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hedging-climate-change-news">Hedging Climate Change News</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#encoder-models">Encoder models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ask-bert-how-regulatory-disclosure-of-transition-and-physical-climate-risks-affects-the-cds-term-structure">Ask BERT: How Regulatory Disclosure of Transition and Physical Climate Risks Affects the CDS Term Structure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#climate-value-and-values-discovery-in-earnings-calls">Climate Value and Values Discovery in Earnings Calls</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Prof. Dr. Ralf Kellner
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>